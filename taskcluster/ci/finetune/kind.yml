# This Source Code Form is subject to the terms of the Mozilla Public
# License, v. 2.0. If a copy of the MPL was not distributed with this
# file, You can obtain one at http://mozilla.org/MPL/2.0/.
---

loader: taskgraph.loader.transform:loader

transforms:
    - translations_taskgraph.transforms.task_substitution_from_params:transforms
    - translations_taskgraph.transforms.from_datasets:locales_only
    - translations_taskgraph.transforms.command_context_from_params:transforms
    - translations_taskgraph.transforms.marian_args:transforms
    - translations_taskgraph.transforms.ensemble:transforms
    - taskgraph.transforms.job:transforms
    - translations_taskgraph.transforms.cache:transforms
    - taskgraph.transforms.cached_tasks:transforms
    - taskgraph.transforms.task:transforms

kind-dependencies:
    - merge
    - train
    - train-vocab
    - toolchain

task-defaults:
    attributes:
        cache:
            resources:
                - pipeline/train/train.sh
    dataset-config:
        substitution-fields:
            - description
            - name
            - treeherder.symbol
            - fetches
            - dependencies
    task-substitution:
        from-parameters:
            best_model: training_config.experiment.best-model
        substitution-fields:
            - fetches.train-teacher
    worker-type: t-linux-v100-gpu
    worker:
        env:
            # TODO: what should we _actually_ use for the workspace value?
            # and should we centralize this, since it seems to depend on available
            # memory?
            WORKSPACE: "8000"
            # TODO: this needs to be updated, ideally to have the script detect
            # GPUs. it should _always_ be aligned with the # of GPUs on the intsance
            GPUS: "0"
            ARTIFACT_EXT: zst
        artifacts:
            - name: public/build
              path: artifacts
              type: directory

    # Don't run unless explicitly scheduled
    run-on-tasks-for: []

    run:
        using: run-task
        command-context:
            from-parameters:
                best_model: training_config.experiment.best-model
        command:
            - bash
            - -c
            - >-
                export MARIAN=$MOZ_FETCHES_DIR &&
                $VCS_PATH/pipeline/train/train.sh
                {model_type}
                train
                {trg_locale}
                {src_locale}
                $MOZ_FETCHES_DIR/{train_set_prefix}
                $MOZ_FETCHES_DIR/{valid_set_prefix}
                $TASK_WORKDIR/artifacts
                $MOZ_FETCHES_DIR/vocab.spm
                {best_model}
                --pretrained-model
                $MOZ_FETCHES_DIR/final.model.npz.best-{best_model}.npz
                {marian_args}

    dependencies:
        train-vocab: train-vocab-{src_locale}-{trg_locale}
        merge-devset: merge-devset-{src_locale}-{trg_locale}

    fetches:
        toolchain:
            - marian
        train-vocab:
            - artifact: vocab.spm
              extract: false
        merge-devset:
            - artifact: devset.{src_locale}.zst
              extract: false
            - artifact: devset.{trg_locale}.zst
              extract: false


tasks:
    "teacher-{src_locale}-{trg_locale}":
        description: finetune teacher for {src_locale}-{trg_locale}
        # ensemble means make N of these tasks
        # TODO: this should come from the pipeline config
        ensemble-config:
            number:
                from-parameters: training_config.experiment.teacher-ensemble
            direction: out
            fields:
                - name
                - description
                - treeherder.symbol
                - dependencies.train-teacher
        attributes:
            stage: finetune-teacher
            cache:
                type: finetune-teacher
                resources:
                    - pipeline/train/configs/model/teacher.yml
                    - pipeline/train/configs/training/teacher.train.yml
                from-parameters:
                    marian_args: training_config.marian-args.training-teacher-finetuned
        worker:
            max-run-time: 86400

        treeherder:
            symbol: "{src_locale}-{trg_locale}"
            platform: finetune-teacher/opt
        marian-args:
            from-parameters: training_config.marian-args.training-teacher-finetuned
        run:
            command-context:
                model_type: teacher
                train_set_prefix: corpus
                valid_set_prefix: devset

        dependencies:
            merge-corpus: merge-corpus-{src_locale}-{trg_locale}
            train-teacher: train-teacher-{src_locale}-{trg_locale}

        fetches:
            merge-corpus:
                - artifact: corpus.{src_locale}.zst
                  extract: false
                - artifact: corpus.{trg_locale}.zst
                  extract: false
            train-teacher:
                - artifact: final.model.npz.best-{best_model}.npz
                  extract: false
